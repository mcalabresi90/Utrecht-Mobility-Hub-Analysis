{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1f407df",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### Shared Mobility Data Wrangling\n",
    "\n",
    "1. **Data Loading**:\n",
    "    - The notebook starts by defining functions to load data from CSV files for different services (`Cargoroo`, `OVFiets`, and `CROW`).\n",
    "    - These functions handle reading files, adding metadata (e.g., service type, modality), and extracting timestamps from filenames.\n",
    "\n",
    "2. **Combining Data**:\n",
    "    - Data from multiple folders (representing different timestamps) is loaded and combined into a single dataframe using the `load_all_mobility_data` function.\n",
    "    - This ensures all data collected over 24 hours is consolidated for analysis.\n",
    "\n",
    "3. **Initial Data Inspection**:\n",
    "    - The combined dataframe is inspected for missing values (`isnull().sum()`) and duplicate rows (`duplicated().sum()`).\n",
    "    - Missing values in critical columns like `modality` are identified and reviewed.\n",
    "\n",
    "4. **Data Cleaning**:\n",
    "    - Duplicate rows are removed to ensure data integrity.\n",
    "    - The `timestamp` column is converted to a consistent datetime format to facilitate time-based analysis.\n",
    "    - Additional columns (`date_only` and `time_only`) are created by splitting the `timestamp` into separate date and time components.\n",
    "\n",
    "5. **Data Export**:\n",
    "    - The cleaned and enriched dataframe is saved to a CSV file for further use.\n",
    "    - Separate CSV files for each service (`Cargoroo`, `OVFiets`, and `CROW`) can also be exported if needed.\n",
    "\n",
    "6. **Geospatial Data Preparation**:\n",
    "    - A GeoDataFrame is created by converting latitude and longitude into geometry points.\n",
    "    - The data is reprojected to the Amersfoort / RD New coordinate system for geospatial analysis.\n",
    "    - The geospatial data is exported as a GeoJSON file for use in GIS tools like QGIS.\n",
    "\n",
    "This process ensures that the data collected over 24 hours is cleaned, structured, and ready for analysis or visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e217be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "from datetime import date\n",
    "from geopy.distance import geodesic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b37baac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['09-04-2025', '10-04-2025', '11-04-2025']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from config import RAW_DIR\n",
    "folder_path = RAW_DIR / \"CSV_vehicle_locations\"\n",
    "print(os.listdir(folder_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b21689",
   "metadata": {},
   "source": [
    "### FUNCTIONS TO EXTRACT DATA FROM THE CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f63c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cargoroo_data(folder_path):\n",
    "    dfs = []\n",
    "    files = glob.glob(os.path.join(folder_path, \"Cargoroo_locations_*.csv\"))\n",
    "    print(f\"ğŸ“ Cargoroo files matched: {len(files)}\")\n",
    "\n",
    "    for file in files:\n",
    "        print(f\"ğŸ”„ Reading: {os.path.basename(file)}\")\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            df[\"service\"] = \"Cargoroo\"\n",
    "            df[\"modality\"] = df.get(\"modality\", \"cargobike\")\n",
    "            df[\"available\"] = 1\n",
    "\n",
    "            time_str = os.path.basename(file).replace(\"Cargoroo_locations_\", \"\").replace(\".csv\", \"\")\n",
    "            df[\"timestamp\"] = pd.to_datetime(time_str, format=\"%d-%m-%Y_%H-%M\")\n",
    "\n",
    "            dfs.append(df[[\"service\", \"modality\", \"latitude\", \"longitude\", \"available\", \"timestamp\"]])\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error reading {file}: {e}\")\n",
    "\n",
    "    if dfs:\n",
    "        print(f\"âœ… Loaded {sum(len(df) for df in dfs)} rows for Cargoroo\")\n",
    "        return pd.concat(dfs, ignore_index=True)\n",
    "    else:\n",
    "        print(\"âš ï¸ No valid Cargoroo data found.\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62aa9008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion OVfiets_data\n",
    "# This function loads OVfiets data from CSV files in the specified folder path.\n",
    "# It assumes that the CSV files have a specific naming convention and structure.\n",
    "# The function reads each file, adds service and modality columns, and selects relevant columns.\n",
    "# Finally, it concatenates all the dataframes into a single dataframe and returns it.  \n",
    "\n",
    "def load_ovfiets_data(folder_path):\n",
    "    dfs = []\n",
    "    files = glob.glob(os.path.join(folder_path, \"OVFiets_locations_*.csv\"))\n",
    "    print(f\"ğŸ“ OVFiets files matched: {len(files)}\")\n",
    "\n",
    "    for file in files:\n",
    "        print(f\"ğŸ”„ Reading: {os.path.basename(file)}\")\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            df[\"service\"] = \"OVFiets\"\n",
    "            df[\"modality\"] = \"bicycle\"\n",
    "\n",
    "            time_str = os.path.basename(file).replace(\"OVFiets_locations_\", \"\").replace(\".csv\", \"\")\n",
    "            df[\"timestamp\"] = pd.to_datetime(time_str, format=\"%d-%m-%Y_%H-%M\")\n",
    "\n",
    "            dfs.append(df[[\"service\", \"modality\", \"latitude\", \"longitude\", \"available\", \"timestamp\"]])\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error reading {file}: {e}\")\n",
    "\n",
    "    if dfs:\n",
    "        print(f\"âœ… Loaded {sum(len(df) for df in dfs)} rows for OVFiets\")\n",
    "        return pd.concat(dfs, ignore_index=True)\n",
    "    else:\n",
    "        print(\"âš ï¸ No valid OVFiets data found.\")\n",
    "        return pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afbf9580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_crow_data(folder_path):\n",
    "    dfs = []\n",
    "    files = glob.glob(os.path.join(folder_path, \"CROW_locations_*.csv\"))\n",
    "    print(f\"ğŸ“ CROW files matched: {len(files)}\")\n",
    "\n",
    "    for file in files:\n",
    "        print(f\"ğŸ”„ Reading: {os.path.basename(file)}\")\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "\n",
    "            # Rename form_factor and system_id\n",
    "            if \"form_factor\" in df.columns and \"system_id\" in df.columns:\n",
    "                df = df.rename(columns={\"form_factor\": \"modality\", \"system_id\": \"service\"})\n",
    "            else:\n",
    "                print(f\"âš ï¸ Missing expected columns in {file}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Clean up modality column (strip spaces + lowercase)\n",
    "            df[\"modality\"] = df[\"modality\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "            # Normalize modality values\n",
    "            modality_map = {\n",
    "                \"cargo_bicycle\": \"cargobike\",\n",
    "                \"bicycle\": \"bicycle\",\n",
    "                \"e-scooter\": \"scooter\",\n",
    "                \"kick_scooter\": \"scooter\",\n",
    "                \"e-bike\": \"bicycle\"\n",
    "            }\n",
    "\n",
    "            df[\"modality\"] = df[\"modality\"].map(modality_map).fillna(df[\"modality\"])\n",
    "\n",
    "            df[\"available\"] = 1\n",
    "\n",
    "            # Extract timestamp from filename\n",
    "            filename = os.path.basename(file)\n",
    "            time_str = filename.replace(\"CROW_locations_\", \"\").replace(\".csv\", \"\")\n",
    "            df[\"timestamp\"] = pd.to_datetime(time_str, format=\"%d-%m-%Y_%H-%M\")\n",
    "\n",
    "            dfs.append(df[[\"service\", \"modality\", \"latitude\", \"longitude\", \"available\", \"timestamp\"]])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error reading {file}: {e}\")\n",
    "\n",
    "    if dfs:\n",
    "        total_rows = sum(len(d) for d in dfs)\n",
    "        print(f\"âœ… Loaded {total_rows} rows for CROW\")\n",
    "        return pd.concat(dfs, ignore_index=True)\n",
    "    else:\n",
    "        print(\"âš ï¸ No valid CROW data found.\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b907c9d",
   "metadata": {},
   "source": [
    "### Load the data per folder (date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f1df59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Cargoroo files matched: 17\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_10-14.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_10-35.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_10-37.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_10-56.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_11-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_12-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_13-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_14-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_15-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_16-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_17-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_18-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_19-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_20-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_21-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_22-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_23-00.csv\n",
      "âœ… Loaded 3026 rows for Cargoroo\n",
      "ğŸ“ OVFiets files matched: 17\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_10-14.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_10-35.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_10-37.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_10-56.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_11-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_12-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_13-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_14-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_15-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_16-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_17-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_18-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_19-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_20-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_21-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_22-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_23-00.csv\n",
      "âœ… Loaded 850 rows for OVFiets\n",
      "ğŸ“ CROW files matched: 16\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_10-35.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_10-37.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_10-56.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_11-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_12-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_13-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_14-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_15-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_16-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_17-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_18-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_19-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_20-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_21-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_22-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_23-00.csv\n",
      "âœ… Loaded 25052 rows for CROW\n"
     ]
    }
   ],
   "source": [
    "from config import RAW_DIR\n",
    "folder_09 = RAW_DIR / \"CSV_vehicle_locations\" / \"09-04-2025\"\n",
    "df_09_cargoroo = load_cargoroo_data(folder_09)\n",
    "df_09_ovfiets = load_ovfiets_data(folder_09)\n",
    "df_09_crow = load_crow_data(folder_09)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c94d7765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3026 rows in cargoroo\n",
      "850 rows in ovfiets\n",
      "25052 rows in crow\n"
     ]
    }
   ],
   "source": [
    "print(len(df_09_cargoroo), \"rows in cargoroo\")\n",
    "print(len(df_09_ovfiets), \"rows in ovfiets\")\n",
    "print(len(df_09_crow), \"rows in crow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb28464f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Cargoroo files matched: 9\n",
      "ğŸ”„ Reading: Cargoroo_locations_10-04-2025_00-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_10-04-2025_01-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_10-04-2025_02-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_10-04-2025_03-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_10-04-2025_09-08.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_10-04-2025_10-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_10-04-2025_11-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_10-04-2025_12-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_10-04-2025_13-00.csv\n",
      "âœ… Loaded 1602 rows for Cargoroo\n",
      "ğŸ“ OVFiets files matched: 9\n",
      "ğŸ”„ Reading: OVFiets_locations_10-04-2025_00-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_10-04-2025_01-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_10-04-2025_02-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_10-04-2025_03-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_10-04-2025_09-08.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_10-04-2025_10-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_10-04-2025_11-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_10-04-2025_12-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_10-04-2025_13-00.csv\n",
      "âœ… Loaded 450 rows for OVFiets\n",
      "ğŸ“ CROW files matched: 9\n",
      "ğŸ”„ Reading: CROW_locations_10-04-2025_00-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_10-04-2025_01-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_10-04-2025_02-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_10-04-2025_03-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_10-04-2025_09-08.csv\n",
      "ğŸ”„ Reading: CROW_locations_10-04-2025_10-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_10-04-2025_11-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_10-04-2025_12-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_10-04-2025_13-00.csv\n",
      "âœ… Loaded 14966 rows for CROW\n"
     ]
    }
   ],
   "source": [
    "from config import RAW_DIR\n",
    "folder_10 = RAW_DIR / \"CSV_vehicle_locations\" / \"10-04-2025\"\n",
    "df_10_cargoroo = load_cargoroo_data(folder_10)\n",
    "df_10_ovfiets = load_ovfiets_data(folder_10)\n",
    "df_10_crow = load_crow_data(folder_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae470f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1602 rows in cargoroo\n",
      "450 rows in ovfiets\n",
      "14966 rows in crow\n"
     ]
    }
   ],
   "source": [
    "print(len(df_10_cargoroo), \"rows in cargoroo\")\n",
    "print(len(df_10_ovfiets), \"rows in ovfiets\")\n",
    "print(len(df_10_crow), \"rows in crow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c84de3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Cargoroo files matched: 11\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_06-30.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_07-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_08-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_09-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_10-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_11-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_12-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_13-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_14-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_16-23.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_17-00.csv\n",
      "âœ… Loaded 1958 rows for Cargoroo\n",
      "ğŸ“ OVFiets files matched: 11\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_06-30.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_07-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_08-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_09-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_10-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_11-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_12-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_13-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_14-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_16-24.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_17-00.csv\n",
      "âœ… Loaded 550 rows for OVFiets\n",
      "ğŸ“ CROW files matched: 11\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_06-30.csv\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_07-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_08-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_09-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_10-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_11-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_12-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_13-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_14-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_16-23.csv\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_17-00.csv\n",
      "âœ… Loaded 17247 rows for CROW\n"
     ]
    }
   ],
   "source": [
    "from config import RAW_DIR\n",
    "folder_11 = RAW_DIR / \"CSV_vehicle_locations\" / \"11-04-2025\"\n",
    "df_11_cargoroo = load_cargoroo_data(folder_11)\n",
    "df_11_ovfiets = load_ovfiets_data(folder_11)\n",
    "df_11_crow = load_crow_data(folder_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fb59a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1958 rows in cargoroo\n",
      "550 rows in ovfiets\n",
      "17247 rows in crow\n"
     ]
    }
   ],
   "source": [
    "print(len(df_11_cargoroo), \"rows in cargoroo\")\n",
    "print(len(df_11_ovfiets), \"rows in ovfiets\")\n",
    "print(len(df_11_crow), \"rows in crow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4877d6",
   "metadata": {},
   "source": [
    "### Function to load all mobility data at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32dae445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all mobility data from the specified root folder\n",
    "# This function loads mobility data from multiple subfolders within a specified root folder.\n",
    "# It processes each subfolder, loads data from Cargoroo, OVFiets, and CROW, and combines the data into a single dataframe.\n",
    "# The function also handles errors during file reading and prints messages accordingly.\n",
    "# The function is designed to be reusable, allowing it to be called multiple times with different root folders if needed.\n",
    "# The function is also designed to be flexible, allowing it to handle different file formats and structures.\n",
    "# The function is designed to work with multiple datasets, making it suitable for various data sources.\n",
    "# The function is designed to be used in a larger data processing pipeline, where multiple datasets are loaded and combined for analysis.\n",
    "\n",
    "\n",
    "def load_all_mobility_data(root_folder):\n",
    "    all_data = []\n",
    "\n",
    "    # Loop through each subfolder (e.g. \"09-04-2025\", \"10-04-2025\", ...)\n",
    "    for folder_name in sorted(os.listdir(root_folder)):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n Processing folder: {folder_name}\")\n",
    "\n",
    "        df_cargoroo = load_cargoroo_data(folder_path)\n",
    "        df_ovfiets = load_ovfiets_data(folder_path)\n",
    "        df_crow = load_crow_data(folder_path)\n",
    "\n",
    "        # Combine all dataframes for the day\n",
    "        daily_df = pd.concat([df_cargoroo, df_ovfiets, df_crow], ignore_index=True)\n",
    "\n",
    "        if not daily_df.empty:\n",
    "            daily_df[\"date_folder\"] = folder_name  # optional: adds the folder name as context\n",
    "            all_data.append(daily_df)\n",
    "\n",
    "    if all_data:\n",
    "        full_df = pd.concat(all_data, ignore_index=True)\n",
    "        print(f\"\\n Finished. Total rows combined: {len(full_df)}\")\n",
    "        return full_df\n",
    "    else:\n",
    "        print(\"\\n No valid data found in any folder.\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb004e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing folder: 09-04-2025\n",
      "ğŸ“ Cargoroo files matched: 17\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_10-14.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_10-35.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_10-37.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_10-56.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_11-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_12-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_13-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_14-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_15-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_16-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_17-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_18-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_19-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_20-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_21-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_22-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_09-04-2025_23-00.csv\n",
      "âœ… Loaded 3026 rows for Cargoroo\n",
      "ğŸ“ OVFiets files matched: 17\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_10-14.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_10-35.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_10-37.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_10-56.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_11-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_12-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_13-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_14-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_15-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_16-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_17-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_18-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_19-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_20-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_21-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_22-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_09-04-2025_23-00.csv\n",
      "âœ… Loaded 850 rows for OVFiets\n",
      "ğŸ“ CROW files matched: 16\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_10-35.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_10-37.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_10-56.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_11-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_12-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_13-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_14-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_15-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_16-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_17-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_18-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_19-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_20-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_21-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_22-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_09-04-2025_23-00.csv\n",
      "âœ… Loaded 25052 rows for CROW\n",
      "\n",
      " Processing folder: 10-04-2025\n",
      "ğŸ“ Cargoroo files matched: 9\n",
      "ğŸ”„ Reading: Cargoroo_locations_10-04-2025_00-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_10-04-2025_01-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_10-04-2025_02-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_10-04-2025_03-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_10-04-2025_09-08.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_10-04-2025_10-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_10-04-2025_11-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_10-04-2025_12-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_10-04-2025_13-00.csv\n",
      "âœ… Loaded 1602 rows for Cargoroo\n",
      "ğŸ“ OVFiets files matched: 9\n",
      "ğŸ”„ Reading: OVFiets_locations_10-04-2025_00-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_10-04-2025_01-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_10-04-2025_02-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_10-04-2025_03-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_10-04-2025_09-08.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_10-04-2025_10-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_10-04-2025_11-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_10-04-2025_12-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_10-04-2025_13-00.csv\n",
      "âœ… Loaded 450 rows for OVFiets\n",
      "ğŸ“ CROW files matched: 9\n",
      "ğŸ”„ Reading: CROW_locations_10-04-2025_00-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_10-04-2025_01-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_10-04-2025_02-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_10-04-2025_03-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_10-04-2025_09-08.csv\n",
      "ğŸ”„ Reading: CROW_locations_10-04-2025_10-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_10-04-2025_11-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_10-04-2025_12-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_10-04-2025_13-00.csv\n",
      "âœ… Loaded 14966 rows for CROW\n",
      "\n",
      " Processing folder: 11-04-2025\n",
      "ğŸ“ Cargoroo files matched: 11\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_06-30.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_07-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_08-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_09-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_10-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_11-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_12-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_13-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_14-00.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_16-23.csv\n",
      "ğŸ”„ Reading: Cargoroo_locations_11-04-2025_17-00.csv\n",
      "âœ… Loaded 1958 rows for Cargoroo\n",
      "ğŸ“ OVFiets files matched: 11\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_06-30.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_07-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_08-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_09-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_10-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_11-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_12-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_13-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_14-00.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_16-24.csv\n",
      "ğŸ”„ Reading: OVFiets_locations_11-04-2025_17-00.csv\n",
      "âœ… Loaded 550 rows for OVFiets\n",
      "ğŸ“ CROW files matched: 11\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_06-30.csv\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_07-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_08-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_09-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_10-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_11-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_12-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_13-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_14-00.csv\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_16-23.csv\n",
      "ğŸ”„ Reading: CROW_locations_11-04-2025_17-00.csv\n",
      "âœ… Loaded 17247 rows for CROW\n",
      "\n",
      " Finished. Total rows combined: 65701\n",
      "    service   modality   latitude  longitude  available           timestamp  \\\n",
      "0  Cargoroo  cargobike  52.083815   5.120739          1 2025-04-09 10:14:00   \n",
      "1  Cargoroo  cargobike  52.083984   5.112088          1 2025-04-09 10:14:00   \n",
      "2  Cargoroo  cargobike  52.071042   5.123966          1 2025-04-09 10:14:00   \n",
      "3  Cargoroo  cargobike  52.076362   5.112459          1 2025-04-09 10:14:00   \n",
      "4  Cargoroo  cargobike  52.072093   5.117056          1 2025-04-09 10:14:00   \n",
      "\n",
      "  date_folder  \n",
      "0  09-04-2025  \n",
      "1  09-04-2025  \n",
      "2  09-04-2025  \n",
      "3  09-04-2025  \n",
      "4  09-04-2025  \n",
      "Index(['service', 'modality', 'latitude', 'longitude', 'available',\n",
      "       'timestamp', 'date_folder'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from config import RAW_DIR\n",
    "root_path = RAW_DIR / \"CSV_vehicle_locations\"\n",
    "all_mobility_data = load_all_mobility_data(str(root_path))\n",
    "print(all_mobility_data.head())\n",
    "print(all_mobility_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e365c782",
   "metadata": {},
   "source": [
    "### Clean the combined dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02eb2b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "service        0\n",
       "modality       0\n",
       "latitude       0\n",
       "longitude      0\n",
       "available      0\n",
       "timestamp      0\n",
       "date_folder    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mobility_data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ec14207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [service, modality, latitude, longitude, available, timestamp, date_folder]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "missing_mobility = all_mobility_data['modality'].isna().sum() # Check for missing values in the 'modality' column\n",
    "missing_mobility_rows = all_mobility_data[all_mobility_data['modality'].isna()]\n",
    "print(missing_mobility_rows.head(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7b0198b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4076"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mobility_data.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "965368cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      service modality   latitude  longitude  available           timestamp  \\\n",
      "3881  moveyou  bicycle  52.084479   5.179265          1 2025-04-09 10:35:00   \n",
      "3882  moveyou  bicycle  52.084479   5.179265          1 2025-04-09 10:35:00   \n",
      "3884  moveyou  bicycle  52.084224   5.167485          1 2025-04-09 10:35:00   \n",
      "3885  moveyou  bicycle  52.084000   5.174200          1 2025-04-09 10:35:00   \n",
      "3886  moveyou  bicycle  52.084000   5.174200          1 2025-04-09 10:35:00   \n",
      "\n",
      "     date_folder  \n",
      "3881  09-04-2025  \n",
      "3882  09-04-2025  \n",
      "3884  09-04-2025  \n",
      "3885  09-04-2025  \n",
      "3886  09-04-2025  \n"
     ]
    }
   ],
   "source": [
    "dupes = all_mobility_data[all_mobility_data.duplicated()]\n",
    "print(dupes.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26321a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      service modality   latitude  longitude  available           timestamp  \\\n",
      "3881  moveyou  bicycle  52.084479   5.179265          1 2025-04-09 10:35:00   \n",
      "3882  moveyou  bicycle  52.084479   5.179265          1 2025-04-09 10:35:00   \n",
      "3884  moveyou  bicycle  52.084224   5.167485          1 2025-04-09 10:35:00   \n",
      "3885  moveyou  bicycle  52.084000   5.174200          1 2025-04-09 10:35:00   \n",
      "3886  moveyou  bicycle  52.084000   5.174200          1 2025-04-09 10:35:00   \n",
      "\n",
      "     date_folder  \n",
      "3881  09-04-2025  \n",
      "3882  09-04-2025  \n",
      "3884  09-04-2025  \n",
      "3885  09-04-2025  \n",
      "3886  09-04-2025  \n"
     ]
    }
   ],
   "source": [
    "all_mobility_data = all_mobility_data.drop_duplicates()\n",
    "print(dupes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6946827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "service\n",
       "greenwheels           17757\n",
       "mywheels              15919\n",
       "check                 14002\n",
       "Cargoroo               6586\n",
       "OVFiets                1850\n",
       "donkey                 1596\n",
       "baqme                  1558\n",
       "tier2                  1008\n",
       "deelfietsnederland      540\n",
       "felyx                   413\n",
       "moveyou                 396\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mobility_data[\"service\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e0b0d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-09 10:14:00\n",
      "2025-04-11 17:00:00\n"
     ]
    }
   ],
   "source": [
    "print(all_mobility_data[\"timestamp\"].min())\n",
    "print(all_mobility_data[\"timestamp\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77348409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the timestamp column to datetime format\n",
    "# This ensures that the timestamp is in a consistent format for further analysis.\n",
    "all_mobility_data[\"timestamp\"] = pd.to_datetime(all_mobility_data[\"timestamp\"], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a238ee0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mobility_data[\"timestamp\"].isnull().sum()  # Check for any null values in the timestamp column after conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a17b0c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date_only</th>\n",
       "      <th>time_only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-09 10:14:00</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>10:14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-09 10:14:00</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>10:14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-09 10:14:00</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>10:14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-09 10:14:00</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>10:14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-09 10:14:00</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>10:14:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp   date_only time_only\n",
       "0 2025-04-09 10:14:00  2025-04-09  10:14:00\n",
       "1 2025-04-09 10:14:00  2025-04-09  10:14:00\n",
       "2 2025-04-09 10:14:00  2025-04-09  10:14:00\n",
       "3 2025-04-09 10:14:00  2025-04-09  10:14:00\n",
       "4 2025-04-09 10:14:00  2025-04-09  10:14:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure timestamp is in datetime format\n",
    "all_mobility_data[\"timestamp\"] = pd.to_datetime(all_mobility_data[\"timestamp\"], errors=\"coerce\")\n",
    "\n",
    "# Split into clean date and time columns\n",
    "all_mobility_data[\"date_only\"] = all_mobility_data[\"timestamp\"].dt.date  # YYYY-MM-DD\n",
    "all_mobility_data[\"time_only\"] = all_mobility_data[\"timestamp\"].dt.time  # HH:MM:SS\n",
    "\n",
    "# Optional: drop the original messy date column\n",
    "all_mobility_data.drop(columns=[\"date_folder\"], inplace=True)\n",
    "\n",
    "\n",
    "display(all_mobility_data[[\"timestamp\", \"date_only\", \"time_only\"]].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a682c41",
   "metadata": {},
   "source": [
    "### Save the cleaned data to a CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665183bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned and enriched mobility data to CSV\n",
    "from config import PROCESSED_DIR\n",
    "output_path = PROCESSED_DIR / \"combined_mobility_data_clean.csv\"\n",
    "\n",
    "# Export to CSV with proper datetime format\n",
    "all_mobility_data.to_csv(output_path, index=False, date_format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "print(\"âœ… Cleaned data exported to:\", output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018eddeb",
   "metadata": {},
   "source": [
    "#### <h4 style=\"color:red;\">Change the boolean to True to run these cells:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7491704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save individual file for Cargoroo\n",
    "# change the boolean to True to export the file\n",
    "\n",
    "if False:\n",
    "    \n",
    "    cargoroo_path = os.path.join(root_path, \"cargoroo_data.csv\")\n",
    "    df_cargoroo = all_mobility_data[all_mobility_data[\"service\"] == \"Cargoroo\"]\n",
    "    df_cargoroo.to_csv(cargoroo_path, index=False)\n",
    "    print(\"âœ… Cargoroo data exported to:\", cargoroo_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save individual file for ovfiets\n",
    "\n",
    "if False:\n",
    "\n",
    "    ovfiets_path = os.path.join(root_path, \"ovfiets_data.csv\")\n",
    "    df_ovfiets = all_mobility_data[all_mobility_data[\"service\"] == \"OVFiets\"]       \n",
    "    df_ovfiets.to_csv(ovfiets_path, index=False)\n",
    "    print(\"âœ… OVFiets data exported to:\", ovfiets_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b7964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save individual file for crow\n",
    "\n",
    "if False:\n",
    "    crow_path = os.path.join(root_path, \"crow_data.csv\")\n",
    "    df_crow = all_mobility_data[all_mobility_data[\"service\"] == \"CROW\"]\n",
    "    df_crow.to_csv(crow_path, index=False)\n",
    "    print(\"âœ… CROW data exported to:\", crow_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467f0dd1",
   "metadata": {},
   "source": [
    "### Export GEODATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919d88c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Create geometry from lat/lon\n",
    "all_mobility_data[\"geometry\"] = gpd.points_from_xy(all_mobility_data[\"longitude\"], all_mobility_data[\"latitude\"])\n",
    "all_mobility_gdf = gpd.GeoDataFrame(all_mobility_data, geometry=\"geometry\")\n",
    "\n",
    "# First set the original CRS to WGS84 (because it's lat/lon)\n",
    "all_mobility_gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "# Then reproject to Amersfoort / RD New\n",
    "all_mobility_gdf = all_mobility_gdf.to_crs(epsg=28992)\n",
    "\n",
    "# Save to GeoJSON\n",
    "from config import QGIS_DIR\n",
    "output_geojson_path = QGIS_DIR / \"shared_mobility_data_combined.geojson\"\n",
    "all_mobility_gdf.to_file(output_geojson_path, driver=\"GeoJSON\")\n",
    "\n",
    "print(\"âœ… GeoJSON exported for QGIS:\", output_geojson_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
